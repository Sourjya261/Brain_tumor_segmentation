{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6578224,"sourceType":"datasetVersion","datasetId":3798716},{"sourceId":6709651,"sourceType":"datasetVersion","datasetId":3866838}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-11-01T13:02:02.273861Z","iopub.execute_input":"2023-11-01T13:02:02.274464Z","iopub.status.idle":"2023-11-01T13:02:41.939369Z","shell.execute_reply.started":"2023-11-01T13:02:02.274420Z","shell.execute_reply":"2023-11-01T13:02:41.938437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Define the paths to the two slice folders\ndata_dir1 = '/kaggle/input/brats-2020-slices/slices-20230925T215308Z-001/slices'\ndata_dir2 = '/kaggle/input/brats-2020-slices/slices-20230925T215308Z-002/slices'\n\n# Get a list of image file names from both folders\nimage_files1 = os.listdir(os.path.join(data_dir1, 'images'))\nimage_files2 = os.listdir(os.path.join(data_dir2, 'images'))\n\n# Initialize empty lists to store image and mask paths\nimage_paths = []\nmask_paths = []\n\n# Loop through image files from slices1 and check for corresponding masks\nfor image_file in image_files1:\n    image_path = os.path.join(data_dir1, 'images', image_file)\n    mask_file = image_file.replace(\"_image.npy\", \"_mask.npy\")\n    mask_path = os.path.join(data_dir1, 'masks', mask_file)\n    \n    image_paths.append(image_path)\n    # Check if the corresponding mask file exists in slices1->masks\n    if os.path.exists(mask_path):\n        #image_paths.append(image_path)\n        mask_paths.append(mask_path)\n    else:\n        #image_paths.append(image_path)\n        mask_path = os.path.join(data_dir2, 'masks', mask_file)\n        mask_paths.append(mask_path)\n        \n\n# Loop through image files from slices2 and check for corresponding masks\nfor image_file in image_files2:\n    image_path = os.path.join(data_dir2, 'images', image_file)\n    mask_file = image_file.replace(\"_image.npy\", \"_mask.npy\")\n    mask_path = os.path.join(data_dir2, 'masks', mask_file)\n    \n    image_paths.append(image_path)\n    # Check if the corresponding mask file exists in slices2->masks\n    if os.path.exists(mask_path):\n        #image_paths.append(image_path)\n        mask_paths.append(mask_path)\n    else:\n       # image_paths.append(image_path)\n        mask_path = os.path.join(data_dir1, 'masks', mask_file)\n        mask_paths.append(mask_path)\n        \n        \n\n# Create a DataFrame to store the paths\ndata = pd.DataFrame({'image_path': image_paths, 'mask_path': mask_paths})","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:03:46.908035Z","iopub.execute_input":"2023-11-01T13:03:46.908635Z","iopub.status.idle":"2023-11-01T13:04:15.399566Z","shell.execute_reply.started":"2023-11-01T13:03:46.908602Z","shell.execute_reply":"2023-11-01T13:04:15.398789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to check if a mask has less than 1% positive pixels\nimport numpy as np\ndef has_few_positive_pixels(mask_path, threshold=0.03):\n    mask = np.load(mask_path)\n    positive_pixels = np.sum(mask[:,:,2] > 0)\n    total_pixels = mask.size\n    return (positive_pixels / total_pixels) < threshold\n\n# Apply the function to the mask_path column\ndata['has_few_positive_pixels'] = data['mask_path'].apply(has_few_positive_pixels)\n\n# Filter rows based on the condition\ndata = data[~data['has_few_positive_pixels']]\n\n# Reset the index if needed\ndata.reset_index(drop=True, inplace=True)\n\n# Remove the temporary column\ndata.drop('has_few_positive_pixels', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T12:30:06.645365Z","iopub.execute_input":"2023-11-01T12:30:06.646150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot images and masks\nimport matplotlib.pyplot as plt\ndef plot_images_masks(images, masks):\n    num_samples = images.shape[0]\n\n    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 10))\n    for i in range(num_samples):\n        axes[i, 0].imshow(images[i],cmap='bone',interpolation='bicubic')\n        axes[i, 0].set_title('Image')\n        axes[i, 0].axis('on')\n\n        axes[i, 1].imshow(masks[i],cmap='bone',interpolation='bicubic')\n        axes[i, 1].set_title('Mask')\n        axes[i, 1].axis('on')\n\n        print(np.max(images[i]),np.max(masks[i]),masks[i].shape)\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:45.433980Z","iopub.execute_input":"2023-11-01T13:04:45.434344Z","iopub.status.idle":"2023-11-01T13:04:45.442138Z","shell.execute_reply.started":"2023-11-01T13:04:45.434314Z","shell.execute_reply":"2023-11-01T13:04:45.441194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define data generator parameters\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='constant'\n)\n\n# Function to load and preprocess images and masks\ndef load_and_preprocess(paths):\n    images = []\n    masks = []\n    for img_path, mask_path in zip(paths['image_path'], paths['mask_path']):\n        img = np.load(img_path).astype(np.float32)\n        mask = np.load(mask_path).astype(np.float32)\n        \"\"\"mask[:,:,0]=(mask[:,:,0]>0).astype(int)\n        mask[:,:,1]=(mask[:,:,1]>0).astype(int)\n        mask[:,:,2]=(mask[:,:,2]>0).astype(int)\n        new_channel = np.zeros((128, 128, 1), dtype=np.float32)\n        mask_4_channel = np.concatenate((new_channel,mask), axis=-1)\"\"\"\n        mask_=(mask[:,:,2]>0).astype(int)\n        mask_=np.expand_dims(mask_,axis=-1)\n        \n        images.append(img)\n        masks.append(mask_)\n    return np.array(images), np.array(masks)\n\n# Function to apply augmentations to both images and masks\ndef apply_augmentation(images, masks):\n    seed = np.random.randint(1, 1000)  # Generate a random seed for augmentations\n    image_gen = datagen.flow(images, batch_size=len(images), seed=seed)\n    mask_gen = datagen.flow(masks, batch_size=len(masks), seed=seed)\n    return next(image_gen), next(mask_gen)\n\n# Generate augmented batches of data with synchronized augmentations\ndef generate_data_generator(data, batch_size):\n    while True:\n        batch_indices = np.random.choice(len(data), batch_size)\n        batch_data = data.iloc[batch_indices]\n        x, y = load_and_preprocess(batch_data)\n        x_augmented, y_augmented = apply_augmentation(x, y)\n        yield x_augmented, y_augmented\n\n# Example usage\nbatch_size = 4\ntrain_data = generate_data_generator(data, batch_size)\n\n# Plot the batch\nbatch_images, batch_masks = next(train_data)\nplot_images_masks(batch_images, batch_masks)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:22.557105Z","iopub.execute_input":"2023-11-01T13:04:22.557449Z","iopub.status.idle":"2023-11-01T13:04:38.598770Z","shell.execute_reply.started":"2023-11-01T13:04:22.557420Z","shell.execute_reply":"2023-11-01T13:04:38.597805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epsilon = 1e-5\nsmooth = 1\n\ndef iou(targets, inputs, smooth=1e-6):\n    \n    #flatten label and prediction tensors\n    class_num = 2\n    for i in range(class_num):\n        targets_f= K.flatten(targets[:,:,:,i])\n        inputs_f = K.flatten(inputs[:,:,:,i])\n       \n\n        intersection = K.sum((targets_f*inputs_f))\n        total = K.sum(targets_f) + K.sum(inputs_f)\n        union = total - intersection\n        loss = (intersection + smooth) / (union + smooth)\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n    total_loss = total_loss / class_num\n    return total_loss\n\ndef iou_tc(targets, inputs, smooth=1e-6):\n    \n    #flatten label and prediction tensors\n    targets_f = K.flatten(targets[:,:,:,1])\n    inputs_f = K.flatten(inputs[:,:,:,1])\n    \n    intersection = K.sum((targets_f * inputs_f))\n    total = K.sum(targets_f) + K.sum(inputs_f)\n    union = total - intersection\n    \n    IoU = (intersection + smooth) / (union + smooth)\n    return IoU\n\ndef tversky(y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef focal_tversky(y_true,y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n\nfrom keras import backend as K\n\ndef dice_coeff(y_true, y_pred, smooth=1):\n    y_true_flatten = K.flatten(y_true)\n    y_pred_flatten = K.flatten(y_pred)\n    intersection = K.sum(y_true_flatten * y_pred_flatten)\n    dice = (2. * intersection + smooth) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) + smooth)\n    return dice\ndef dice_loss(y_true, y_pred, smooth=1):\n    return  1- dice_coeff(y_true, y_pred, smooth=1)\n\ndef FocalLoss(targets, inputs, alpha=0.8, gamma=2):    \n    \n    inputs = K.flatten(inputs)\n    targets = K.flatten(targets)\n    \n    BCE = K.binary_crossentropy(targets, inputs)\n    BCE_EXP = K.exp(-BCE)\n    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n    \n    return focal_loss\n\ndef total_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    return dice_loss(y_true, y_pred, smooth=1) + FocalLoss(y_true, y_pred, 0.25,2)\n\ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:04:54.985202Z","iopub.execute_input":"2023-11-01T13:04:54.985563Z","iopub.status.idle":"2023-11-01T13:04:55.007566Z","shell.execute_reply.started":"2023-11-01T13:04:54.985535Z","shell.execute_reply":"2023-11-01T13:04:55.006641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,Conv2DTranspose, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Input, ZeroPadding2D,Dropout,Dense,MaxPooling2D,Reshape,Multiply,GlobalAveragePooling2D,AveragePooling2D,Lambda\nfrom tensorflow.keras.models import Model\nfrom sklearn.decomposition import NMF\n\ndef batchnorm_relu(inputs):\n    x = BatchNormalization(axis=-1)(inputs)\n    x = Activation(\"relu\")(x)\n    return x\ndef ASPP(x, filter):\n    shape = x.shape\n\n    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n    y1 = Conv2D(filter, 1, padding=\"same\")(y1)\n    y1 = BatchNormalization()(y1)\n    y1 = Activation(\"relu\")(y1)\n    y1 = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y1)\n\n    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(x)\n    y2 = BatchNormalization()(y2)\n    y2 = Activation(\"relu\")(y2)\n\n    y3 = Conv2D(filter, 3, dilation_rate=3, padding=\"same\", use_bias=False)(x)\n    y3 = BatchNormalization()(y3)\n    y3 = Activation(\"relu\")(y3)\n\n    y4 = Conv2D(filter, 3, dilation_rate=5, padding=\"same\", use_bias=False)(x)\n    y4 = BatchNormalization()(y4)\n    y4 = Activation(\"relu\")(y4)\n\n    y5 = Conv2D(filter, 3, dilation_rate=7, padding=\"same\", use_bias=False)(x)\n    y5 = BatchNormalization()(y5)\n    y5 = Activation(\"relu\")(y5)\n\n    y = Concatenate()([y1, y2, y3, y4, y5])\n\n    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False)(y)\n    y = BatchNormalization()(y)\n    y = Activation(\"relu\")(y)\n\n    return y\n\n\ndef GCSE(input_tensor, ratio=8, i=0):\n    \n  \n    # Compute the global statistics (mean and std deviation) along the channel axis.\n    mean = tf.reduce_mean(input_tensor, axis=[1, 2], keepdims=True)\n    std = tf.math.reduce_std(input_tensor, axis=[1, 2], keepdims=True)\n    \n    # Compute channel-wise attention using a convolutional neural network.\n    attn_channel = tf.concat([mean, std], axis=-1)\n    attn_channel = tf.keras.layers.Conv2D(filters=input_tensor.shape[-1] // ratio, kernel_size=(1, 1), activation='relu',name=\"first_channel_attention_\"+str(i))(attn_channel)\n    attn_channel = tf.keras.layers.Conv2D(filters=input_tensor.shape[-1], kernel_size=(1, 1), activation='sigmoid',name=\"second_channel_attention_\"+str(i))(attn_channel)\n    \n    # Compute spatial attention using global information from the input tensor.\n    global_info = tf.reduce_mean(input_tensor, axis=-1, keepdims=True)\n    attn_spatial = tf.keras.layers.Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid',name=\"spatial_attention_\"+str(i))(global_info)\n    \n    # Combine channel-wise and spatial attention.\n    attn = tf.keras.layers.Multiply(name='combined_attention_'+str(i))([attn_channel,attn_spatial])\n    \n    # Multiply the input tensor by the learned attention weights.\n    output_tensor = tf.keras.layers.Multiply(name='SE_out_'+str(i))([input_tensor,attn])\n    \n    return output_tensor\n\ndef residual_block(inputs, num_filters):\n    \"\"\" Convolutional Layer \"\"\"\n    x = batchnorm_relu(inputs)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=1,kernel_initializer = \"he_normal\")(x)\n    x = Dropout(0.1)(x)\n    x = batchnorm_relu(x)\n    x = Conv2D(num_filters, 3, padding=\"same\", strides=1,kernel_initializer = \"he_normal\")(x)\n    #x = squeeze_excite_block(x,8)\n\n    \"\"\" Shortcut Connection \"\"\"\n    s = Conv2D(num_filters, 1, padding=\"same\", strides=1,kernel_initializer=\"he_normal\")(inputs)\n    x = x + s\n    return x\n\ndef decoder_block(inputs, skip_features, num_filters,i):\n    x = Conv2DTranspose(num_filters,2, strides=(2,2), kernel_initializer=\"he_normal\",padding = \"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    x = residual_block(x, num_filters)\n    x = GCSE(x,i=i)\n    return x\n\ndef build_resunet(input_shape):\n    inputs = Input(input_shape)\n    \n    #integrating augmentation directly into the model\n    #x = tf.keras.layers.RandomContrast(0.15)(inputs)\n    #x = tf.keras.layers.RandomTranslation(height_factor=0.2, width_factor=0.2)(x)\n    #x = tf.keras.layers.RandomFlip(\"horizontal_and_vertical\")(x)\n    #x_ = tf.keras.layers.RandomZoom(0.3)(x)\n    \n   \n\n    \n\n    \"\"\" Encoder 1 \"\"\"\n    x = Conv2D(32, 3, padding=\"same\", strides=1,kernel_initializer=\"he_normal\")(inputs)\n    x = batchnorm_relu(x)\n    x = Conv2D(32, 3, padding=\"same\", strides=1,kernel_initializer=\"he_normal\")(x)\n    s = Conv2D(32, 1, padding=\"same\", strides=1,kernel_initializer=\"he_normal\")(inputs)\n    \n    c1 = x + s\n    c1 =GCSE(c1,i=1)\n    p1 = MaxPooling2D((2,2))(c1)\n    s1 = residual_block(c1,32)\n    #s1 = c1\n\n    \"\"\" Encoder 2 and 3 \"\"\"\n    c2 = residual_block(p1, 64)\n    c2 = GCSE(c2,i=2)\n    p2 = MaxPooling2D((2,2))(c2)\n    s2 = residual_block(c2,64)\n    #s2 = c2\n    \n    c3 = residual_block(p2, 128)\n    c3 =GCSE(c3,i=4)\n    p3 = MaxPooling2D((2,2))(c3)\n    s3 = residual_block(c3,128)\n    #s3 = c3\n\n    c4 = residual_block(p3, 256)\n    c4 = GCSE(c4,i=5)\n    p4 = MaxPooling2D((2,2))(c4)\n    s4 = residual_block(c4,256)\n    #s4 = c4\n\n    \"\"\" Bridge \"\"\"\n    b = ASPP(p4,256)\n    #b = p4\n\n    \"\"\" Decoder 1, 2, 3 \"\"\"\n    d1 = decoder_block(b, s4, 256,i=6)\n    d2 = decoder_block(d1, s3, 128,i=7)\n    d3 = decoder_block(d2, s2, 64,i=8)\n    d4 = decoder_block(d3, s1, 32,i=9)\n\n    \"\"\" Classifier \"\"\"\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    \"\"\" Model \"\"\"\n    model = Model(inputs, outputs)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:50:52.258757Z","iopub.execute_input":"2023-11-01T13:50:52.259526Z","iopub.status.idle":"2023-11-01T13:50:52.290029Z","shell.execute_reply.started":"2023-11-01T13:50:52.259494Z","shell.execute_reply":"2023-11-01T13:50:52.289192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install -U segmentation-models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:05:19.195005Z","iopub.execute_input":"2023-11-01T13:05:19.196121Z","iopub.status.idle":"2023-11-01T13:05:34.977285Z","shell.execute_reply.started":"2023-11-01T13:05:19.196087Z","shell.execute_reply":"2023-11-01T13:05:34.976289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compling model and callbacks functions\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import CSVLogger\nmodel = build_resunet((128,128,3))\nadam = tf.keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer = adam, \n                  loss = total_loss, \n                  metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5),dice_coeff,precision,sensitivity,specificity,tf.keras.metrics.AUC()]\n                 )\n#callbacks\ncsv_logger = CSVLogger('/kaggle/working/training_log_et', separator=',', append=False)\nearlystopping = EarlyStopping(monitor='val_loss',\n                              mode='min', \n                              verbose=1, \n                              patience=8\n                             )\n# save the best model with lower validation loss\ncheckpointer = ModelCheckpoint(filepath=\"/kaggle/working/seg_model_et.h5\", \n                               verbose=1, \n                               save_best_only=True,\n                               save_weights_only=True\n                              )\n                              \nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              mode='min',\n                              verbose=1,\n                              patience=4,\n                              min_delta=0.000001,\n                              factor=0.2\n                             )\ncallbacks = [checkpointer, reduce_lr, csv_logger]","metadata":{"execution":{"iopub.status.busy":"2023-10-16T10:17:04.067747Z","iopub.execute_input":"2023-10-16T10:17:04.068170Z","iopub.status.idle":"2023-10-16T10:17:05.107558Z","shell.execute_reply.started":"2023-10-16T10:17:04.068138Z","shell.execute_reply":"2023-10-16T10:17:05.106567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Define batch size\nbatch_size = 8\n\n# Create data generators for training and validation sets\ntrain_generator = generate_data_generator(train_data, batch_size)\nval_generator = generate_data_generator(val_data, batch_size)\n\ntrain_steps_per_epoch = len(train_data) // batch_size\nval_steps_per_epoch = len(val_data) // batch_size\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T09:24:16.135860Z","iopub.execute_input":"2023-10-16T09:24:16.136245Z","iopub.status.idle":"2023-10-16T09:24:16.143926Z","shell.execute_reply.started":"2023-10-16T09:24:16.136206Z","shell.execute_reply":"2023-10-16T09:24:16.142800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator, \n                  steps_per_epoch=train_steps_per_epoch,\n                  epochs = 50, \n                  validation_data = val_generator,\n                  validation_steps=val_steps_per_epoch,\n                  callbacks = callbacks\n                 )","metadata":{"execution":{"iopub.status.busy":"2023-10-16T10:17:10.471764Z","iopub.execute_input":"2023-10-16T10:17:10.472840Z","iopub.status.idle":"2023-10-16T10:22:44.266527Z","shell.execute_reply.started":"2023-10-16T10:17:10.472795Z","shell.execute_reply":"2023-10-16T10:22:44.265371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = pd.read_csv('/kaggle/input/brats20-slices-training-and-log-et/training_log_et', sep=',', engine='python')\n\n#hist=history.history\n\n############### ########## ####### #######\n\niou_score=history['iou_score']\nval_iou_score=history['val_iou_score']\n\nloss=history['loss']\nval_loss=history['val_loss']\n\ntrain_dice=history['dice_coeff']\nval_dice=history['val_dice_coeff']\n\nepoch = np.arange(len(loss))\n\n# Create subplots\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\nplt.subplots_adjust(wspace=0.3)  # Adjust the space between subplots\n\n# Plot 1: Loss\naxes[0].plot(epoch, loss, 'b', label='Training Loss', linewidth=1.5)\naxes[0].plot(epoch, val_loss, 'r', label='Validation Loss', linewidth=1.5)\naxes[0].set_xlabel('Epochs')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training and Validation Loss')\naxes[0].legend()\n\n# Plot 2: IOU Scores\naxes[1].plot(epoch, iou_score, 'b', label='Training IOU', linewidth=1.5)\naxes[1].plot(epoch, val_iou_score, 'r', label='Validation IOU', linewidth=1.5)\naxes[1].set_xlabel('Epochs')\naxes[1].set_ylabel('IOU Score')\naxes[1].set_title('Training and Validation IOU Score')\naxes[1].legend()\n\n# Plot 3: Dice Coefficients\naxes[2].plot(epoch, train_dice, 'b', label='Training Dice Coeff', linewidth=1.5)\naxes[2].plot(epoch, val_dice, 'r', label='Validation Dice Coeff', linewidth=1.5)\naxes[2].set_xlabel('Epochs')\naxes[2].set_ylabel('Dice Coefficient')\naxes[2].set_title('Training and Validation Dice Coefficient')\naxes[2].legend()\n\n# Customize tick marks and labels\nfor ax in axes:\n    ax.grid(True)\n    ax.set_xticks(np.arange(0, len(epoch), 5))  # Adjust the x-axis ticks\n    ax.set_yticks(np.arange(0, 1.1, 0.1))  # Adjust the y-axis ticks\n    ax.grid(which='both', linestyle='--', linewidth=0.5)\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T10:48:35.691969Z","iopub.execute_input":"2023-10-16T10:48:35.692355Z","iopub.status.idle":"2023-10-16T10:48:37.411327Z","shell.execute_reply.started":"2023-10-16T10:48:35.692327Z","shell.execute_reply":"2023-10-16T10:48:37.410434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_resunet((128,128,3))","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:51:03.032042Z","iopub.execute_input":"2023-11-01T13:51:03.032420Z","iopub.status.idle":"2023-11-01T13:51:04.364109Z","shell.execute_reply.started":"2023-11-01T13:51:03.032390Z","shell.execute_reply":"2023-11-01T13:51:04.363314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:51:06.341905Z","iopub.execute_input":"2023-11-01T13:51:06.342269Z","iopub.status.idle":"2023-11-01T13:51:06.840380Z","shell.execute_reply.started":"2023-11-01T13:51:06.342240Z","shell.execute_reply":"2023-11-01T13:51:06.839406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"/kaggle/input/brats20-slices-training-and-log-et/seg_model_et (1).h5\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:09:11.851884Z","iopub.execute_input":"2023-11-01T13:09:11.852536Z","iopub.status.idle":"2023-11-01T13:09:12.517968Z","shell.execute_reply.started":"2023-11-01T13:09:11.852505Z","shell.execute_reply":"2023-11-01T13:09:12.517140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\ns = time.time()\nans = model.predict(batch_images)\ne = time.time()\nprint(e-s)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:51:32.453312Z","iopub.execute_input":"2023-11-01T13:51:32.454219Z","iopub.status.idle":"2023-11-01T13:51:32.539786Z","shell.execute_reply.started":"2023-11-01T13:51:32.454184Z","shell.execute_reply":"2023-11-01T13:51:32.538835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_images.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:11:22.608754Z","iopub.execute_input":"2023-11-01T13:11:22.609565Z","iopub.status.idle":"2023-11-01T13:11:22.615205Z","shell.execute_reply.started":"2023-11-01T13:11:22.609536Z","shell.execute_reply":"2023-11-01T13:11:22.614413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_images, batch_masks = next(train_data)\n#plot_images_masks(batch_images, batch_masks)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:25:12.120306Z","iopub.execute_input":"2023-11-01T13:25:12.121024Z","iopub.status.idle":"2023-11-01T13:25:12.219781Z","shell.execute_reply.started":"2023-11-01T13:25:12.120994Z","shell.execute_reply":"2023-11-01T13:25:12.218712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = time.time()\nans = model.predict(batch_images)\ne = time.time()\nprint(e-s)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:25:15.346354Z","iopub.execute_input":"2023-11-01T13:25:15.346717Z","iopub.status.idle":"2023-11-01T13:25:15.427959Z","shell.execute_reply.started":"2023-11-01T13:25:15.346687Z","shell.execute_reply":"2023-11-01T13:25:15.427058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import concatenate\nimport keras\n#Step 2: Define the U-net model with Depth=4\ndef unet(pretrained_weights = None,input_size = (256,256,1)):\n    inputs = tf.keras.Input(shape=input_size)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    drop4 = Dropout(0.5)(conv4, training=True)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    drop5 = Dropout(0.5)(conv5, training=True)\n\n    up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n\n    up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n    \n\n    up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n    \n\n    up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n   \n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n\n    #model.compile(optimizer = tf.optimizers.Adam(lr = 0.0001), loss = total_loss, metrics = dice_coeff)\n    \n\n    if(pretrained_weights):\n    \tmodel=keras.models.load_model(pretrained_weights)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:46:50.404233Z","iopub.execute_input":"2023-11-01T13:46:50.404640Z","iopub.status.idle":"2023-11-01T13:46:50.430040Z","shell.execute_reply.started":"2023-11-01T13:46:50.404603Z","shell.execute_reply":"2023-11-01T13:46:50.429089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet = unet(pretrained_weights = None,input_size=(128,128,3))","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:46:53.707080Z","iopub.execute_input":"2023-11-01T13:46:53.707804Z","iopub.status.idle":"2023-11-01T13:46:54.113447Z","shell.execute_reply.started":"2023-11-01T13:46:53.707772Z","shell.execute_reply":"2023-11-01T13:46:54.112635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = time.time()\nans = unet.predict(batch_images)\ne = time.time()\nprint(e-s)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:47:00.808084Z","iopub.execute_input":"2023-11-01T13:47:00.808916Z","iopub.status.idle":"2023-11-01T13:47:00.884880Z","shell.execute_reply.started":"2023-11-01T13:47:00.808882Z","shell.execute_reply":"2023-11-01T13:47:00.884000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T13:47:04.121569Z","iopub.execute_input":"2023-11-01T13:47:04.121981Z","iopub.status.idle":"2023-11-01T13:47:04.239063Z","shell.execute_reply.started":"2023-11-01T13:47:04.121947Z","shell.execute_reply":"2023-11-01T13:47:04.238175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}